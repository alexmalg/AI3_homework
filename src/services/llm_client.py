# ============================================================================
# llm_client.py - LLM API –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å MentorPiece API
# ============================================================================


import requests
import json
from typing import Optional
from src.config import Config


class LLMClient:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å LLM API (MentorPiece).
    """

    def __init__(self):
        self.api_endpoint = Config.API_ENDPOINT
        self.api_key = Config.API_KEY
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        self.timeout = 30

    def call_llm(self, model_name: str, prompt: str) -> Optional[str]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –≤—ã–∑–æ–≤–∞ LLM –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ API.
        
        –†–ï–ñ–ò–ú–´ –†–ê–ë–û–¢–´:
        1. –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º (ENABLE_MOCKS=False): —Ä–µ–∞–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∫ API
        2. –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º Cypress (ENABLE_MOCKS=True): –º–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
        3. Pytest —Ç–µ—Å—Ç—ã: –∏—Å–ø–æ–ª—å–∑—É—é—Ç @mock.patch, –Ω–µ –∑–∞–≤–∏—Å—è—Ç –æ—Ç ENABLE_MOCKS
        """
        
        # ====================================================================
        # –†–ï–ñ–ò–ú –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø: –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã –º–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è Cypress
        # ====================================================================
        if Config.ENABLE_MOCKS:
            print(f"üîß MOCK MODE (Cypress): –í–æ–∑–≤—Ä–∞—Ç –º–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞")
            
            # –ú–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            if "Qwen" in model_name:
                print(f"üìö Mock –ø–µ—Ä–µ–≤–æ–¥ –¥–ª—è –º–æ–¥–µ–ª–∏ Qwen")
                return "The sun is shining."
            elif "claude-sonnet" in model_name:
                print(f"üìö Mock –æ—Ü–µ–Ω–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ claude-sonnet")
                return "Rating: 9/10. Fluent and accurate."
            else:
                print(f"üìö Mock –æ—Ç–≤–µ—Ç –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏")
                return "Mocked Response: Default answer"
        
        # ====================================================================
        # –û–ë–´–ß–ù–´–ô –†–ï–ñ–ò–ú: –†–µ–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ API
        # ====================================================================
        
        request_body = {
            "model_name": model_name,
            "prompt": prompt
        }
        
        try:
            print(f"üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ API...")
            print(f"   –ú–æ–¥–µ–ª—å: {model_name}")
            print(f"   –ü—Ä–æ–º–ø—Ç: {prompt[:100]}...")
            
            response = requests.post(
                url=self.api_endpoint,
                json=request_body,
                headers=self.headers,
                timeout=self.timeout
            )
            
            if response.status_code >= 400:
                print(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
                print(f"   –¢–µ–∫—Å—Ç –æ—à–∏–±–∫–∏: {response.text}")
                return None
            
            response_data = response.json()
            
            if "response" not in response_data:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: –∫–ª—é—á 'response' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
                print(f"   –ü–æ–ª—É—á–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {response_data}")
                return None
            
            llm_response = response_data["response"]
            
            print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç API ({len(llm_response)} —Å–∏–º–≤–æ–ª–æ–≤)")
            
            return llm_response
        
        except requests.exceptions.Timeout:
            print(f"‚ùå –û—à–∏–±–∫–∞: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ (—Å–µ—Ä–≤–µ—Ä –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª –∑–∞ {self.timeout} —Å–µ–∫)")
            return None
        
        except requests.exceptions.ConnectionError:
            print(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ API")
            print(f"   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å {self.api_endpoint}")
            return None
        
        except requests.exceptions.RequestException as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ HTTP –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
            return None
        
        except json.JSONDecodeError:
            print(f"‚ùå –û—à–∏–±–∫–∞: –û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º JSON")
            print(f"   –ü–æ–ª—É—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {response.text[:200]}")
            return None
        
        except Exception as e:
            print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
            return None


client = LLMClient()

def call_llm(model_name: str, prompt: str) -> Optional[str]:
    """
    –§—É–Ω–∫—Ü–∏—è-–æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –≤—ã–∑–æ–≤–∞ LLM.
    """
    return client.call_llm(model_name, prompt)
